<html lang="en"><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Running OpenAI Gym Environments · BlueWhale</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta property="og:title" content="Running OpenAI Gym Environments · BlueWhale"/><meta property="og:type" content="website"/><meta property="og:url" content="https://facebookresearch.github.io/BlueWhale/index.html"/><meta property="og:description" content="This guide describes how to run BlueWhale on OpenAI Gym Environments."/><link rel="shortcut icon" href="/BlueWhale/img/logo/icon_light.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><link rel="stylesheet" href="/BlueWhale/css/main.css"/></head><body class="sideNavVisible doc separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/BlueWhale/"><img class="logo" src="/BlueWhale/img/logo/icon_light.png" alt="BlueWhale"/><h2 class="headerTitle">BlueWhale</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="https://github.com/facebookresearch/BlueWhale" target="_self">Fork us on GitHub!</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><i></i></div><h2><i>›</i><span>BlueWhale</span></h2></div><div class="navGroups"><div class="navGroup navGroupActive"><h3>BlueWhale</h3><ul><li class="navListItem"><a class="navItem" href="/BlueWhale/docs/begin.html">Introduction</a></li><li class="navListItem"><a class="navItem" href="/BlueWhale/docs/install.html">Installing</a></li><li class="navListItem navListItemActive"><a class="navItem navItemActive" href="/BlueWhale/docs/openai_gym.html">OpenAI Gym</a></li><li class="navListItem"><a class="navItem" href="/BlueWhale/docs/models.html">Models</a></li><li class="navListItem"><a class="navItem" href="/BlueWhale/docs/contact.html">Contact Us</a></li><li class="navListItem"><a class="navItem" href="/BlueWhale/docs/license.html">License</a></li></ul></div></div></section></div><script>
          var toggler = document.getElementById('navToggler');
          var nav = document.getElementById('docsNav');
          toggler.onclick = function() {
            nav.classList.toggle('docsSliderActive');
          };
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1>Running OpenAI Gym Environments</h1></header><article><div><span><p>This guide describes how to run BlueWhale on OpenAI Gym Environments.</p>
<h2><a class="anchor" aria-hidden="true" id="quickstart"></a><a href="#quickstart" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Quickstart</h2>
<pre><code class="hljs">python ml/rl/test/gym/run_gym<span class="hljs-selector-class">.py</span> -<span class="hljs-selector-tag">p</span> ml/rl/test/gym/maxq_cartpole_v0<span class="hljs-selector-class">.json</span>
</code></pre>
<p>The <a href="https://github.com/facebookresearch/BlueWhale/tree/master/ml/rl/test/gym/run_gym.py">run_gym.py</a> script will construct an RL model and run it in an OpenAI Gym environemnt, periodically reporting scores averaged over several trials. In general, you can run RL models in OpenAI Gym environments with:</p>
<pre><code class="hljs">python ml<span class="hljs-meta-keyword">/rl/</span>test<span class="hljs-meta-keyword">/gym/</span>run_gym.py -p <span class="hljs-params">&lt;parameters_file&gt;</span> [-s <span class="hljs-params">&lt;score_bar&gt;</span>] [-g <span class="hljs-params">&lt;gpu_id&gt;</span>]
</code></pre>
<ul>
<li><strong>parameters_file</strong>: Path to your JSON parameters file</li>
<li><strong>score_bar</strong> (optional): Scalar score you hope to achieve. Once your model scores at least <em>score_bar</em> well averaged over 100 test trials, training will stop and the script will exit. If left empty, training will continue until you complete collect data from <em>num_episodes</em> episodes (see details on parameters in the next section)</li>
<li><strong>gpu_id</strong> (optional): If set to your machine's GPU id (typically <code>0</code>), the model will run its training and inference on your GPU. Otherwise it will use your CPU</li>
</ul>
<p>Feel free to create your own parameter files to select different environments and change model parameters. The success criteria for different environments can be found <a href="https://gym.openai.com/envs">here</a>. We currently supply default arguments for the following environments:</p>
<ul>
<li><a href="https://gym.openai.com/envs/CartPole-v0/">CartPole-v0</a> environment: <a href="https://github.com/facebookresearch/BlueWhale/tree/master/ml/rl/test/gym/maxq_cartpole_v0.json">maxq_cartpole_v0.json</a></li>
<li><a href="https://gym.openai.com/envs/CartPole-v1/">CartPole-v1</a> environment: <a href="https://github.com/facebookresearch/BlueWhale/tree/master/ml/rl/test/gym/maxq_cartpole_v1.json">maxq_cartpole_v1.json</a></li>
<li><a href="https://gym.openai.com/envs/LunarLander-v2/">LunarLander-v2</a> environment: <a href="https://github.com/facebookresearch/BlueWhale/tree/master/ml/rl/test/gym/maxq_lunarlander_v2.json">maxq_lunarlander_v2.json</a></li>
</ul>
<p>Feel free to try out image-based environments too! The parameters we supply will get you a model that runs and trains quickly, not one that performs well:</p>
<ul>
<li><a href="https://gym.openai.com/envs/Asteroids-v0/">Asteroids-v0</a> environment: <a href="https://github.com/facebookresearch/BlueWhale/tree/master/ml/rl/test/gym/maxq_asteroids_v0.json">maxq_asteroids_v0.json</a></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="modifying-the-parameters-file"></a><a href="#modifying-the-parameters-file" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Modifying the parameters file</h2>
<p>As an example, The Cartpole-v0 default parameter file we supply specifies the use of an RL model whose backing neural net has 5 layers:</p>
<pre><code class="hljs css json">{
    <span class="hljs-attr">"env"</span>: <span class="hljs-string">"CartPole-v0"</span>,
    <span class="hljs-attr">"rl"</span>: {
        <span class="hljs-attr">"reward_discount_factor"</span>: <span class="hljs-number">0.99</span>,
        <span class="hljs-attr">"target_update_rate"</span>: <span class="hljs-number">0.1</span>,
        <span class="hljs-attr">"reward_burnin"</span>: <span class="hljs-number">10</span>,
        <span class="hljs-attr">"maxq_learning"</span>: <span class="hljs-number">1</span>,
        <span class="hljs-attr">"epsilon"</span>: <span class="hljs-number">0.2</span>
    },
    <span class="hljs-attr">"training"</span>: {
        <span class="hljs-attr">"layers"</span>: [<span class="hljs-number">-1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">128</span>, <span class="hljs-number">64</span>, <span class="hljs-number">-1</span>],
        <span class="hljs-attr">"activations"</span>: [<span class="hljs-string">"relu"</span>, <span class="hljs-string">"relu"</span>, <span class="hljs-string">"relu"</span>, <span class="hljs-string">"linear"</span>],
        <span class="hljs-attr">"minibatch_size"</span>: <span class="hljs-number">128</span>,
        <span class="hljs-attr">"learning_rate"</span>: <span class="hljs-number">0.005</span>,
        <span class="hljs-attr">"optimizer"</span>: <span class="hljs-string">"ADAM"</span>,
        <span class="hljs-attr">"learning_rate_decay"</span>: <span class="hljs-number">0.999</span>
    },
    <span class="hljs-attr">"run_details"</span>: {
        <span class="hljs-attr">"num_episodes"</span>: <span class="hljs-number">301</span>,
        <span class="hljs-attr">"train_every"</span>: <span class="hljs-number">10</span>,
        <span class="hljs-attr">"train_after"</span>: <span class="hljs-number">10</span>,
        <span class="hljs-attr">"test_every"</span>: <span class="hljs-number">100</span>,
        <span class="hljs-attr">"test_after"</span>: <span class="hljs-number">10</span>,
        <span class="hljs-attr">"num_train_batches"</span>: <span class="hljs-number">100</span>,
        <span class="hljs-attr">"avg_over_num_episodes"</span>: <span class="hljs-number">100</span>,
        <span class="hljs-attr">"render"</span>: <span class="hljs-number">0</span>,
        <span class="hljs-attr">"render_every"</span>: <span class="hljs-number">100</span>
    }
}
</code></pre>
<p>You can supply a different JSON parameter file, modifying the fields to your liking.</p>
<ul>
<li><strong>env</strong>: The OpenAI gym environment to use</li>
<li><strong>rl</strong>
<ul>
<li><strong>reward_discount_factor</strong>: A measure of how quickly the model's target network updates</li>
<li><strong>target_update_rate</strong>: A measure of how quickly the model's target network updates</li>
<li><strong>reward_burnin</strong>: The iteration after which to use the model's target network to construct target values</li>
<li><strong>maxq_learning</strong>: 1 for Q-learning, 0 for SARSA</li>
<li><strong>epsilon</strong>: Fraction of the time the agent should select a random action during training</li>
</ul></li>
<li><strong>training</strong>
<ul>
<li><strong>layers</strong>: An array whose ith entry specifies the number of nodes in the ith layer of the Neural Net. Use <code>-1</code> for the input and output layers; our models will fill in the appropriate values based on your choice of environment</li>
<li><strong>activations</strong>: A array whose ith entry specifies the activation function to use between the ith and i+1th layers. Valid choices are <code>&quot;linear&quot;</code> and <code>&quot;relu&quot;</code>. Note that this array should have one fewer entry than your entry for <em>layers</em></li>
<li><strong>minibatch_size</strong>: The number of transitions to train the Neural Net on at a time. This will not effect the total number of datapoints supplied. In general, lower/higher minibatch sizes perform better with lower/higher learning rates</li>
<li><strong>learning_rate</strong>: Learning rate for the neural net</li>
<li><strong>optimizer</strong>: Neural net weight update algorithm. Valid choices are <code>&quot;SGD&quot;</code>, <code>&quot;ADAM&quot;</code>, <code>&quot;ADAGRAD&quot;</code>, and <code>&quot;FTRL&quot;</code></li>
<li><strong>learning_rate_decay</strong>: Factor by which the learning rate decreases after each training minibatch</li>
</ul></li>
<li><strong>run_details</strong> (reading the code that uses these might be helpful: <a href="https://github.com/facebookresearch/BlueWhale/blob/master/ml/rl/test/gym/run_gym.py#L21">run_gym.py</a>)
<ul>
<li><strong>num_episodes</strong>: Number of episodes run the mode and to collect new data over</li>
<li><strong>train_every</strong>: Number of episodes between each training cycle</li>
<li><strong>train_after</strong> Number of episodes after which to enable training</li>
<li><strong>test_every</strong>: Number of episodes between each test cycle</li>
<li><strong>test_after</strong>: Number of episodes after which to enable testing</li>
<li><strong>num_train_batches</strong>: Number of batches to train over each training cycle</li>
<li><strong>avg_over_num_episodes</strong>: Number of episodes to run every test cycle. After each cycle, the script will report an average over the scores of the episodes run within it.The typical choice is <code>100</code>, but this should be set according to the <a href="https://gym.openai.com/envs">success criteria</a> for your environment</li>
<li><strong>render</strong>: Whether or not to render the OpenAI environment in training and testing episodes. Note that some environments don't support rendering</li>
<li><strong>render_every</strong>: Number of episodes between each rendered episode</li>
</ul></li>
</ul>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="install.html">← Installing BlueWhale</a><a class="docs-next button" href="models.html">Supported Models →</a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#quickstart">Quickstart</a></li><li><a href="#modifying-the-parameters-file">Modifying the parameters file</a></li></ul></nav></div><footer class="nav-footer" id="footer"><a href="https://code.facebook.com/projects/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/BlueWhale/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a></footer></div></body></html>